{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<h3>Student Information</h3> Please provide information about yourself.<br>\n",
    "<b>Name</b>: Shengtao Lin<br>\n",
    "<b>NetID</b>: sl1377<br>\n",
    "<b>Notes to Grader</b> (optional):<br>\n",
    "<br><br>\n",
    "<b>IMPORTANT</b>\n",
    "Your work will not be graded withour your initials below<br>\n",
    "I certify that this lab represents my own work and I have read the RU academic intergrity policies at<br>\n",
    "<a href=\"https://www.cs.rutgers.edu/academic-integrity/introduction\">https://www.cs.rutgers.edu/academic-integrity/introduction </a><br>\n",
    "<b>Initials</b>:SL     \n",
    "\n",
    "\n",
    "<h3>Grader Notes</h3>\n",
    "<b>Your Grade<b>:<br>\n",
    "<b>Grader Initials</b>:<br>\n",
    "<b>Grader Comments</b> (optional):<br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 7: Linear Models, Feature Engineering and Logistic Regression\n",
    "\n",
    "** This lab is due Sunday November 24, 2019 at 11:59pm (graded on accuracy and completeness) **\n",
    "\n",
    "In this lab we will work through the process of:\n",
    "1. implementing a linear model, defining loss functions, \n",
    "2. feature engineering,\n",
    "3. minimizing loss functions using numeric libraries \n",
    "4. how to implement logistic regression model for a binary classification problem\n",
    "\n",
    "We will use the toy tip calculation dataset from sns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "np.random.seed(42)\n",
    "plt.style.use('fivethirtyeight')\n",
    "sns.set()\n",
    "sns.set_context(\"talk\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Tips Dataset\n",
    "\n",
    "To begin with, we load the tips dataset from the `seaborn` library.  The tips data contains records of tips, total bill, and information about the person who paid the bill."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Records: 244\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_bill</th>\n",
       "      <th>tip</th>\n",
       "      <th>sex</th>\n",
       "      <th>smoker</th>\n",
       "      <th>day</th>\n",
       "      <th>time</th>\n",
       "      <th>size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16.99</td>\n",
       "      <td>1.01</td>\n",
       "      <td>Female</td>\n",
       "      <td>No</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.34</td>\n",
       "      <td>1.66</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21.01</td>\n",
       "      <td>3.50</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23.68</td>\n",
       "      <td>3.31</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24.59</td>\n",
       "      <td>3.61</td>\n",
       "      <td>Female</td>\n",
       "      <td>No</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   total_bill   tip     sex smoker  day    time  size\n",
       "0       16.99  1.01  Female     No  Sun  Dinner     2\n",
       "1       10.34  1.66    Male     No  Sun  Dinner     3\n",
       "2       21.01  3.50    Male     No  Sun  Dinner     3\n",
       "3       23.68  3.31    Male     No  Sun  Dinner     2\n",
       "4       24.59  3.61  Female     No  Sun  Dinner     4"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = sns.load_dataset(\"tips\")\n",
    "print(\"Number of Records:\", len(data))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Defining the Model and Feature Engineering\n",
    "\n",
    "In lab 6, we defined a simple linear model with only one parameter. Now let's make a more complicated model that utilizes other features in a dataset. Let our prediction for tip be a combination of the following features:\n",
    "\n",
    "$$\n",
    "\\text{Tip} = \\theta_1 * \\text{total_bill} + \\theta_2 * \\text{sex} + \\theta_3 * \\text{smoker} + \\theta_4 * \\text{day} + \\theta_5 * \\text{time} + \\theta_6 * \\text{size}\n",
    "$$\n",
    "\n",
    "Notice that some of these features are not numbers! But our linear model will need to predict a numerical value. \n",
    "### Task 1.1 Split the data into Y(tip) and X(all others)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## BEGIN SOLUTION\n",
    "tips = data['tip']\n",
    "X = data[['total_bill','sex','smoker','day','time','size']]\n",
    "#print(tips.head())\n",
    "#print(X.head())\n",
    "## END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1.2: Feature Engineering\n",
    "First, let's convert everything to numerical values. A straightforward approach is to map some of these non-numerical features into numerical ones. For example, we can treat the day as a value from 1-7. However, one of the disadvantages in directly translating to a numeric value is that we unintentially assign certain features disproportionate weight. Consider assigning Sunday to the numeric value of 7. Monday is assigned to 1 and thus Sunday has 7 times the influence of Monday in our linear model which can lower the accuracy of our model.\n",
    "\n",
    "solution: one-hot encoding! \n",
    "\n",
    "As discussed in lecture 9.2, one-hot encoding will produce a binary vector indicating the non-numeric feature. Sunday would be encoded as a [0 0 0 0 0 0 1]. This assigns a more even weight across each category in non-numeric features. Complete the code below to one-hot encode our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode(data):\n",
    "    \"\"\"\n",
    "    Return the one-hot encoded dataframe of our input, data. \n",
    "    Hint: check pd.get_dummies\n",
    "    \"\"\"\n",
    "    ### BEGIN SOLUTION\n",
    "\n",
    "    data=pd.get_dummies(data,columns=['sex','smoker','day','time'])\n",
    "    return data\n",
    "    \n",
    "    ### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_bill</th>\n",
       "      <th>size</th>\n",
       "      <th>sex_Male</th>\n",
       "      <th>sex_Female</th>\n",
       "      <th>smoker_Yes</th>\n",
       "      <th>smoker_No</th>\n",
       "      <th>day_Thur</th>\n",
       "      <th>day_Fri</th>\n",
       "      <th>day_Sat</th>\n",
       "      <th>day_Sun</th>\n",
       "      <th>time_Lunch</th>\n",
       "      <th>time_Dinner</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16.99</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.34</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21.01</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23.68</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24.59</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   total_bill  size  sex_Male  sex_Female  smoker_Yes  smoker_No  day_Thur  \\\n",
       "0       16.99     2         0           1           0          1         0   \n",
       "1       10.34     3         1           0           0          1         0   \n",
       "2       21.01     3         1           0           0          1         0   \n",
       "3       23.68     2         1           0           0          1         0   \n",
       "4       24.59     4         0           1           0          1         0   \n",
       "\n",
       "   day_Fri  day_Sat  day_Sun  time_Lunch  time_Dinner  \n",
       "0        0        0        1           0            1  \n",
       "1        0        0        1           0            1  \n",
       "2        0        0        1           0            1  \n",
       "3        0        0        1           0            1  \n",
       "4        0        0        1           0            1  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_X = one_hot_encode(X)\n",
    "one_hot_X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1.2: Defining the Model\n",
    "Now that all of our data is numeric, let's define our model function. Note that X and thetas are matrices now. Use matrix products to compute the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_model(thetas, X):\n",
    "    \"\"\"\n",
    "    Return the linear combination of thetas and features as defined above.\n",
    "    \"\"\"\n",
    "    ### BEGIN SOLUTION\n",
    "\n",
    "    return(np.dot(X,thetas))\n",
    "    \n",
    "    ### END SOLUTION\n",
    "#linear_model(np.arange(1,5), np.arange(1,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert linear_model(np.arange(1,5), np.arange(1,5)) == 30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Fitting the Model: Numeric Methods\n",
    "Recall in the previous lab we defined multiple loss functions and found optimal theta using the scipy.minimize function. Adapt the loss functions and optimization code from the previous lab (provided below) to work with your new linear model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.094487  , 0.1759912 , 0.18411085, 0.21655235, 0.15712761,\n",
       "       0.24353555, 0.01519972, 0.17746092, 0.05600946, 0.15199343,\n",
       "       0.23440129, 0.1662616 ])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.optimize import minimize\n",
    "\n",
    "def abserror(y, y_hat):\n",
    "    return np.abs(y-y_hat)\n",
    "\n",
    "def sqerror(y, y_hat):\n",
    "    return (y - y_hat)**2\n",
    "\n",
    "def minimize_average_loss(loss_function, model, x, y):\n",
    "    \"\"\"\n",
    "    loss_function: either the squared or absolute loss functions from above.\n",
    "    model: the model (as defined above)\n",
    "    x: the x values (one-hot encoded data)\n",
    "    y: the y values (tip amounts)\n",
    "    return the estimate for each theta as a vector\n",
    "    \n",
    "    Note we will ignore failed convergence for this lab ... \n",
    "    \"\"\"\n",
    "    \n",
    "    ## Notes on the following function call which you need to finish:\n",
    "    # \n",
    "    # 0. the ... should be replaced with the average loss evaluated on \n",
    "    #       the data x, y using the model and appropriate loss function\n",
    "    # 1. x0 are the initial values for THETA.  Yes, this is confusing\n",
    "    #       but optimization people like x to be the thing they are \n",
    "    #       optimizing.\n",
    "    # 2. We extract the 'x' entry in the dictionary which corresponds\n",
    "    #       to the value of thetas at the optimum\n",
    "    ### BEGIN SOLUTION\n",
    "    \n",
    "    return minimize(lambda theta: np.sum(loss_function(model(theta, x), y))/len(y), x0=np.zeros(x.shape[1]))['x']\n",
    "    \n",
    "    #return minimize(lambda theta: ..., x0=...)\n",
    "    ### END SOLUTION\n",
    "\n",
    "\n",
    "minimize_average_loss(sqerror, linear_model, one_hot_X, tips)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: Fitting the Model: Analytic Methods\n",
    "Let's also fit our model analytically, for the l2 loss function. In this question we will derive an analytical solution, fit our model and compare our results with our numerical optimization results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3.1: Least Squares Solution\n",
    "Recall that if we're fitting a linear model with the l2 loss function, we are performing least squares! Remember, we are solving the following optimization problem for least squares:\n",
    "\n",
    "$$\\min_{\\theta} ||X\\theta - y||^2$$\n",
    "\n",
    "Let's begin by deriving the analytic solution to least squares. Write your answer in LaTeX in the cell below. Assume X is full column rank."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BEGIN SOLUTION\n",
    "Take the gradient and set theta equal to 0. \n",
    "\n",
    "$$2(X\\theta - y) = 0$$\n",
    "$$ \\nabla((\\theta^TX^T-y^T)(X\\theta-y))=0 $$\n",
    "$$ 2X^TX\\theta-2X^Ty=0$$\n",
    "$$ \\theta = (X^TX)^{-1}X^Ty $$\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3.2: Solving for Theta\n",
    "Now that we have the analytic solution for $\\theta$, let's find the optimal numerical thetas for our tips dataset. Fill out the function below. Make sure you use the float type in your calculations using .astype(float) and use the np.linalg.inv function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_analytical(x, y):\n",
    "    \"\"\"\n",
    "    x: our one-hot encoded dataset\n",
    "    y: tip amounts\n",
    "    \"\"\"\n",
    "    ### BEGIN SOLUTION\n",
    "    xTx = x.astype(float).T.dot(x.astype(float))\n",
    "    xTy = x.astype(float).T.dot(y.astype(float))\n",
    "    return np.linalg.inv(xTx).dot(xTy)\n",
    "    #return np.dot(np.dot(np.linalg.inv(np.dot(x.T.astype(float), x.astype(float))), x.T.astype(float)), y.astype(float))\n",
    "    ### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our analytical loss is:  328.6182469774592\n",
      "Our numerical loss is:  1.010353561236738\n"
     ]
    }
   ],
   "source": [
    "analytical_thetas = get_analytical(one_hot_X.astype(float), tips.astype(float))\n",
    "print(\"Our analytical loss is: \", sqerror(linear_model(analytical_thetas, one_hot_X),tips).mean())\n",
    "print(\"Our numerical loss is: \", sqerror(linear_model(minimize_average_loss(sqerror, linear_model, one_hot_X, tips), one_hot_X), tips).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-afe53110127a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msqerror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinear_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manalytical_thetas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mone_hot_X\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtips\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m59.733414754098362\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "assert np.isclose(sqerror(linear_model(analytical_thetas, one_hot_X),tips).mean(), 59.733414754098362)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3.3: Weird Results?\n",
    "Our analytical loss is surprisingly much worse than our numerical loss. Why is this? \n",
    "\n",
    "Hint: https://stackoverflow.com/questions/31256252/why-does-numpy-linalg-solve-offer-more-precise-matrix-inversions-than-numpy-li"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BEGIN SOLUTION\n",
    "My analytical loss is differetn from the sample output. One reason can be the matrix I got from part 2 has different order than the sample output. The analytical loss is 99.7% worse than the numerical loss. The reason can be np.linalg.inv was used in calculating analytical loss. It will cause more numerical error and more floating point calculation that made the result less accurate.\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 4 - Logistic Regression\n",
    "In this part we will implement a logistic regression model with the tip data set. We will use Male and Female as the binary classification. We will use the LogisiticRegression model from sklearn to find a prediction model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## task 4.1\n",
    "** create the X (one-hot features) and y (sex) **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   total_bill  size  smoker_Yes  smoker_No  day_Thur  day_Fri  day_Sat  \\\n",
      "0       16.99     2           0          1         0        0        0   \n",
      "1       10.34     3           0          1         0        0        0   \n",
      "2       21.01     3           0          1         0        0        0   \n",
      "3       23.68     2           0          1         0        0        0   \n",
      "4       24.59     4           0          1         0        0        0   \n",
      "\n",
      "   day_Sun  time_Lunch  time_Dinner  \n",
      "0        1           0            1  \n",
      "1        1           0            1  \n",
      "2        1           0            1  \n",
      "3        1           0            1  \n",
      "4        1           0            1  \n",
      "0    Female\n",
      "1      Male\n",
      "2      Male\n",
      "3      Male\n",
      "4    Female\n",
      "Name: sex, dtype: category\n",
      "Categories (2, object): [Male, Female]\n"
     ]
    }
   ],
   "source": [
    "## BEGIN SOLTUION\n",
    "X = pd.get_dummies(data,columns=['smoker','day','time']).drop(columns=['sex','tip'])\n",
    "y = data['sex']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## END SOLUTION\n",
    "print(X.head())\n",
    "print(y.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## task 4.2 \n",
    "Split the data set to training and test using sklearn train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     total_bill  size  smoker_Yes  smoker_No  day_Thur  day_Fri  day_Sat  \\\n",
      "115       17.31     2           0          1         0        0        0   \n",
      "181       23.33     2           1          0         0        0        0   \n",
      "225       16.27     2           1          0         0        1        0   \n",
      "68        20.23     2           0          1         0        0        1   \n",
      "104       20.92     2           0          1         0        0        1   \n",
      "\n",
      "     day_Sun  time_Lunch  time_Dinner  \n",
      "115        1           0            1  \n",
      "181        1           0            1  \n",
      "225        0           1            0  \n",
      "68         0           0            1  \n",
      "104        0           0            1        total_bill  size  smoker_Yes  smoker_No  day_Thur  day_Fri  day_Sat  \\\n",
      "24        19.82     2           0          1         0        0        1   \n",
      "6          8.77     2           0          1         0        0        0   \n",
      "153       24.55     4           0          1         0        0        0   \n",
      "211       25.89     4           1          0         0        0        1   \n",
      "198       13.00     2           1          0         1        0        0   \n",
      "\n",
      "     day_Sun  time_Lunch  time_Dinner  \n",
      "24         0           0            1  \n",
      "6          1           0            1  \n",
      "153        1           0            1  \n",
      "211        0           0            1  \n",
      "198        0           1            0   115    Female\n",
      "181      Male\n",
      "225    Female\n",
      "68       Male\n",
      "104    Female\n",
      "Name: sex, dtype: category\n",
      "Categories (2, object): [Male, Female] 24       Male\n",
      "6        Male\n",
      "153      Male\n",
      "211      Male\n",
      "198    Female\n",
      "Name: sex, dtype: category\n",
      "Categories (2, object): [Male, Female]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "## BEGIN SOLUTION\n",
    "\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y)\n",
    "## END SOLUTION\n",
    "\n",
    "print (X_train.head(), X_test.head(), y_train.head(), y_test.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## task 4.3 logistic regression model\n",
    "Fit a logisitic regression model using LogisticRegression from sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
      "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
      "                   warm_start=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/LINHTS/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "## BEGIN SOLUTION\n",
    "\n",
    "logmodel = LogisticRegression().fit(X_train, y_train)\n",
    "print(logmodel)\n",
    "\n",
    "## END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## task 4.4 Predicting\n",
    "Now we can use the logmodel from previous part to predict on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "## BEGIN SOLUTION\n",
    "\n",
    "\n",
    "predictions = logmodel.predict(X_test)\n",
    "#print(predictions)\n",
    "## END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## task 4.5 reporting\n",
    "use classification_report from sklearn.metrics to report the accuracy of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Female       0.30      0.55      0.39        11\n",
      "        Male       0.88      0.72      0.79        50\n",
      "\n",
      "    accuracy                           0.69        61\n",
      "   macro avg       0.59      0.63      0.59        61\n",
      "weighted avg       0.77      0.69      0.72        61\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "## BEGIN SOLUTION\n",
    "\n",
    "\n",
    "print(classification_report(predictions,y_test))\n",
    "\n",
    "## END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feedback\n",
    "Please provide feedback on this lab.\n",
    "* how would you rate this lab (from 1-10, 10-highest) :\n",
    "* how can we improve his lab? :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<h2>Submission Instructions</h2> \n",
    "<b> File Name:</b> Please name the file as your_section_your_netID_lab7.jpynb<br>\n",
    "<b> Submit To: </b> Canvas &rarr; Assignments &rarr; lab7 <br>\n",
    "<b>Warning:</b> Failure to follow directions may result in loss points.<br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Developed by A.D. Gunawardena. Credits: Josh Hug, Berkeley Data Science Lab"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
